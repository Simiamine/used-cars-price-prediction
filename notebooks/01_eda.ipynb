{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrÃ©diction du prix de vÃ©hicules d'occasion (Craigslist) â€“ RÃ©gression par rÃ©seau de neurones et comparaison d'optimiseurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction et contexte du projet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce projet vise Ã  prÃ©dire le prix de vÃ©hicules d'occasion Ã  partir de leurs caractÃ©ristiques, en utilisant un rÃ©seau de neurones.  \n",
    "Nous utilisons le jeu de donnÃ©es *Craigslist Cars and Trucks* (annonces de voitures d'occasion sur Craigslist) fourni par l'utilisateur.  \n",
    "Ce jeu de donnÃ©es est volumineux (~1,45 Go pour ~1,7 million d'enregistrements) et contient de nombreuses informations sur les vÃ©hicules listÃ©s (prix, Ã©tat du vÃ©hicule, constructeur, etc.)â€‹.\n",
    "\n",
    "Nous allons exploiter ces donnÃ©es pour entraÃ®ner un modÃ¨le de rÃ©gression qui estimera le prix de vente Ã  partir des attributs du vÃ©hicule.\n",
    "\n",
    "## L'objectif est doubleÂ :\n",
    "\n",
    "- Construire un modÃ¨le de rÃ©seau de neurones simple pour cette tÃ¢che de rÃ©gression (prÃ©diction de prix).\n",
    "- Ã‰tudier l'influence de diffÃ©rents algorithmes d'optimisation sur la convergence du modÃ¨le et sa performance.  \n",
    "Nous comparerons au minimum **SGD (Stochastic Gradient Descent)** et **Adam**, et potentiellement d'autres optimiseurs adaptatifs comme **RMSprop** ou **Adagrad**.\n",
    "\n",
    "---\n",
    "\n",
    "## Ã‰valuation des performances\n",
    "\n",
    "Nous Ã©valuerons principalement la **MAE (Mean Absolute Error)** comme mÃ©trique de performance, car elle donne une idÃ©e claire de l'erreur moyenne en valeur monÃ©taire (euros) entre le prix prÃ©dit et le prix rÃ©el.\n",
    "\n",
    "La **MSE (Mean Squared Error)** sera Ã©galement observÃ©e (notamment en tant que fonction de perte pour l'entraÃ®nement) afin de dÃ©tecter d'Ã©ventuelles grandes erreurs (puisque MSE pÃ©nalise davantage les Ã©carts Ã©levÃ©s).\n",
    "\n",
    "---\n",
    "\n",
    "## Approche expÃ©rimentale (Ã©tapes)\n",
    "\n",
    "Nous procÃ©derons Ã©tape par Ã©tapeÂ :\n",
    "\n",
    "1. **PrÃ©paration et nettoyage des donnÃ©es**  \n",
    "   â†’ filtrage des colonnes inutiles, gestion des valeurs manquantes, encodage des variables qualitatives (catÃ©gorielles) et normalisation des variables quantitatives.\n",
    "\n",
    "2. **DÃ©finition du modÃ¨le**  \n",
    "   â†’ un rÃ©seau de neurones Ã  2-3 couches *fully connected* avec fonctions d'activation **ReLU** et une sortie **linÃ©aire** adaptÃ©e Ã  la rÃ©gression.\n",
    "\n",
    "3. **EntraÃ®nement avec diffÃ©rents optimiseurs**  \n",
    "   â†’ nous entraÃ®nerons le mÃªme modÃ¨le avec plusieurs algorithmes d'optimisation (**SGD**, **Adam**, **RMSprop**, **Adagrad**) sur un nombre fixe d'Ã©poques (par ex. 100) pour comparer leur vitesse de convergence et leur performance finale.  \n",
    "   â†’ Nous suivrons l'Ã©volution de la **MAE** (et de la loss **MSE**) au fil des Ã©poques pour chaque optimiseur.\n",
    "\n",
    "4. **Mesure des temps d'entraÃ®nement**  \n",
    "   â†’ pour chaque optimiseur, nous mesurerons le temps nÃ©cessaire pour effectuer 100 Ã©poques d'entraÃ®nement, afin de comparer l'efficacitÃ© computationnelle en plus de l'efficacitÃ© en termes de convergence.\n",
    "\n",
    "5. **Comparaison des performances**  \n",
    "   â†’ nous superposerons les courbes de perte et de MAE des diffÃ©rents runs pour visualiser clairement les diffÃ©rences de convergence.  \n",
    "   â†’ Nous comparerons Ã©galement les MAE finales atteintes sur le jeu de validation/test par chaque mÃ©thode.\n",
    "\n",
    "6. **Analyse de l'importance des caractÃ©ristiques**  \n",
    "   â†’ finalement, nous Ã©tudierons l'impact de chaque attribut du jeu de donnÃ©es sur le rÃ©sultat en supprimant les colonnes une Ã  une et en observant l'augmentation de l'erreur (**MAE**) sans cette information.  \n",
    "   â†’ Cette *analyse par ablation* nous permettra d'identifier quelles caractÃ©ristiques sont les plus influentes pour prÃ©dire le prix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrÃ©paration et nettoyage des donnÃ©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, nous allons **charger le jeu de donnÃ©es** et le **prÃ©parer pour l'entraÃ®nement du modÃ¨le**.\r\n",
    "\r\n",
    "### Ã‰tapes rÃ©alisÃ©es :\r\n",
    "\r\n",
    "- **Chargement des donnÃ©es brutes** depuis le fichier CSV.\r\n",
    "\r\n",
    "- **Suppression des colonnes non pertinentes** pour notre objectif :  \r\n",
    "  (ex : identifiants, descriptions textuelles, URL d'images, coordonnÃ©es GPS, etc.), qui nâ€™apportent pas dâ€™information utile pour la prÃ©diction du prix.\r\n",
    "\r\n",
    "- **Gestion des valeurs manquantes** :  \r\n",
    "  Pour simplifier, on choisit ici de supprimer les lignes incomplÃ¨tes. Cette approche est acceptable compte tenu de la **taille importante du dataset**.\r\n",
    "\r\n",
    "- **Transformation de la date** (`posting_date`) :  \r\n",
    "  Elle est convertie en format date/heure, puis utilisÃ©e pour extraire des **features temporelles** (annÃ©e, mois, jour de la semaine), utiles pour capturer dâ€™Ã©ventuels effets saisonniers ou tendances.\r\n",
    "\r\n",
    "- **Filtrage des outliers** :  \r\n",
    "  On garde uniquement les annonces dont le **prix est rÃ©aliste** (par exemple entre **100â‚¬ et 250â€¯000â‚¬**) pour Ã©viter que des valeurs aberrantes perturbent lâ€™apprentissage du modÃ¨le.\r\n",
    "\r\n",
    "- **SÃ©paration des caractÃ©ristiques et de la cible** :  \r\n",
    "  La colonne `price` est la **variable cible** Ã  prÃ©dire, les autres colonnes seront les **features explicatives**.\r\n",
    "\r\n",
    "- **Encodage des variables catÃ©gorielles** :  \r\n",
    "  Les variables comme `manufacturer`, `condition`, `fuel`, `transmission`, etc. sont transformÃ©es par **One-Hot Encoding** : chaque catÃ©gorie devient une **colonne binaire** (0 ou 1) indiquant sa prÃ©sence.\r\n",
    "\r\n",
    "- **Normalisation des variables numÃ©riques** :  \r\n",
    "  Les colonnes comme `year`, `odometer`, etc. ont des **Ã©chelles diffÃ©rentes**.  \r\n",
    "  Elles sont standardisÃ©es (**soustraction de la moyenne**, **division par lâ€™Ã©cart-type**) pour accÃ©lÃ©rer et stabiliser lâ€™entraÃ®nement.  \r\n",
    "  âš ï¸ La cible `price` **nâ€™est pas normalisÃ©e**, pour conserver une interprÃ©tation directe des erreurs (MAE en euros).\r\n",
    "\r\n",
    "- **DÃ©coupage en ensembles dâ€™entraÃ®nement, validation et test** :  \r\n",
    "  Typiquement :  \r\n",
    "  - 70% pour lâ€™entraÃ®nement  \r\n",
    "  - 15% pour la validation  \r\n",
    "  - 15% pour le test  \r\n",
    "  La **validation** est utilisÃ©e pendant lâ€™entraÃ®nement pour surveiller la performance sur des donnÃ©es non vues.  \r\n",
    "  La sÃ©paration est **alÃ©atoire**, avec un `random_state` fixÃ© pour assurer la reproductibilitÃ©.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "ExÃ©cutons ces Ã©tapes **une par une**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du jeu de donnÃ©es et sÃ©lection des colonnes utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "Dans le dataset original, les colonnes disponibles incluent (entre autres) :\r\n",
    "\r\n",
    "`region`, `price`, `year`, `manufacturer`, `model`, `condition`, `cylinders`, `fuel`,  \r\n",
    "`odometer`, `title_status`, `transmission`, `drive`, `size`, `type`, `lat`, `long`,  \r\n",
    "`posting_date`, `state`, etc.\r\n",
    "\r\n",
    "Toutes **ne sont pas pertinentes** pour prÃ©dire le prix. Voici pourquoi certaines seront ignorÃ©es :\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### âŒ Colonnes exclues :\r\n",
    "\r\n",
    "- **`region`** et **`county`** : trop locales ou redondantes avec l'Ã‰tat (`state`).\r\n",
    "- **`lat`** / **`long`** : coordonnÃ©es GPS trop prÃ©cises, peu utiles pour une estimation globale.\r\n",
    "- **`VIN`** : identifiant unique sans utilitÃ© dans une modÃ©lisation globale.\r\n",
    "- **`url`, `region_url`, `image_url`** : liens d'annonce, inutiles ici.\r\n",
    "- **`description`** : texte libre non structurÃ© que nous ne traiterons pas ici.\r\n",
    "- **`id`** : identifiant unique de lâ€™annonce.\r\n",
    "- **`model`** : bien quâ€™informatif, il y a **trop de valeurs distinctes** (ex : \"Corolla\", \"F-150\"...).  \r\n",
    "  Pour cette premiÃ¨re version, nous le laissons de cÃ´tÃ© pour Ã©viter une complexitÃ© excessive.  \r\n",
    "  La **marque** (`manufacturer`) suffira Ã  capter lâ€™effet du modÃ¨le.\r\n",
    "- **`size`** : remplacÃ©e implicitement par `type` (berline, SUV, etc.).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### âœ… Colonnes conservÃ©es :\r\n",
    "\r\n",
    "- **`price`** : cible Ã  prÃ©dire.\r\n",
    "- **`year`** : annÃ©e de mise en circulation du vÃ©hicule.\r\n",
    "- **`manufacturer`** : marque du vÃ©hicule (Toyota, Fordâ€¦).\r\n",
    "- **`condition`** : Ã©tat du vÃ©hicule (neuf, excellent, bonâ€¦).\r\n",
    "- **`cylinders`** : nombre de cylindres (catÃ©goriel dans le dataset).\r\n",
    "- **`fuel`** : type de carburant (essence, diesel, Ã©lectriqueâ€¦).\r\n",
    "- **`odometer`** : kilomÃ©trage.\r\n",
    "- **`transmission`** : type de boÃ®te de vitesses (manuelle, automatiqueâ€¦).\r\n",
    "- **`drive`** : type de traction (propulsion, traction, 4x4â€¦).\r\n",
    "- **`type`** : type de vÃ©hicule (pickup, berline, SUVâ€¦).\r\n",
    "- **`paint_color`** : couleur extÃ©rieure.\r\n",
    "- **`state`** : code de lâ€™Ã‰tat (USA).\r\n",
    "- **`title_status`** : Ã©tat administratif du vÃ©hicule (clean, rebuilt, salvageâ€¦).\r\n",
    "- **`posting_date`** : date de publication de lâ€™annonce  \r\n",
    "  â¤ On lâ€™utilisera pour **extraire des informations temporelles** (annÃ©e, mois, jour).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "ğŸ”§ **Nous allons maintenant procÃ©der au chargement du dataset et au filtrage initial des colonnes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions initiales du dataset : (426880, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>region</th>\n",
       "      <th>region_url</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>...</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>image_url</th>\n",
       "      <th>description</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>posting_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7222695916</td>\n",
       "      <td>https://prescott.craigslist.org/cto/d/prescott...</td>\n",
       "      <td>prescott</td>\n",
       "      <td>https://prescott.craigslist.org</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>az</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7218891961</td>\n",
       "      <td>https://fayar.craigslist.org/ctd/d/bentonville...</td>\n",
       "      <td>fayetteville</td>\n",
       "      <td>https://fayar.craigslist.org</td>\n",
       "      <td>11900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7221797935</td>\n",
       "      <td>https://keys.craigslist.org/cto/d/summerland-k...</td>\n",
       "      <td>florida keys</td>\n",
       "      <td>https://keys.craigslist.org</td>\n",
       "      <td>21000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7222270760</td>\n",
       "      <td>https://worcester.craigslist.org/cto/d/west-br...</td>\n",
       "      <td>worcester / central MA</td>\n",
       "      <td>https://worcester.craigslist.org</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7210384030</td>\n",
       "      <td>https://greensboro.craigslist.org/cto/d/trinit...</td>\n",
       "      <td>greensboro</td>\n",
       "      <td>https://greensboro.craigslist.org</td>\n",
       "      <td>4900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                                url  \\\n",
       "0  7222695916  https://prescott.craigslist.org/cto/d/prescott...   \n",
       "1  7218891961  https://fayar.craigslist.org/ctd/d/bentonville...   \n",
       "2  7221797935  https://keys.craigslist.org/cto/d/summerland-k...   \n",
       "3  7222270760  https://worcester.craigslist.org/cto/d/west-br...   \n",
       "4  7210384030  https://greensboro.craigslist.org/cto/d/trinit...   \n",
       "\n",
       "                   region                         region_url  price  year  \\\n",
       "0                prescott    https://prescott.craigslist.org   6000   NaN   \n",
       "1            fayetteville       https://fayar.craigslist.org  11900   NaN   \n",
       "2            florida keys        https://keys.craigslist.org  21000   NaN   \n",
       "3  worcester / central MA   https://worcester.craigslist.org   1500   NaN   \n",
       "4              greensboro  https://greensboro.craigslist.org   4900   NaN   \n",
       "\n",
       "  manufacturer model condition cylinders  ... size  type paint_color  \\\n",
       "0          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n",
       "1          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n",
       "2          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n",
       "3          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n",
       "4          NaN   NaN       NaN       NaN  ...  NaN   NaN         NaN   \n",
       "\n",
       "  image_url description county state lat long posting_date  \n",
       "0       NaN         NaN    NaN    az NaN  NaN          NaN  \n",
       "1       NaN         NaN    NaN    ar NaN  NaN          NaN  \n",
       "2       NaN         NaN    NaN    fl NaN  NaN          NaN  \n",
       "3       NaN         NaN    NaN    ma NaN  NaN          NaN  \n",
       "4       NaN         NaN    NaN    nc NaN  NaN          NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement des donnÃ©es depuis le fichier CSV\n",
    "import pandas as pd\n",
    "\n",
    "# Lire le fichier CSV (en supposant qu'il est dans le rÃ©pertoire courant ou prÃ©ciser le chemin)\n",
    "df = pd.read_csv(\"../data/vehicles.csv\")\n",
    "\n",
    "# Afficher le nombre de lignes/colonnes initial et un aperÃ§u des premiÃ¨res lignes\n",
    "print(\"Dimensions initiales du dataset :\", df.shape)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions aprÃ¨s suppression de colonnes inutiles : (426880, 14)\n",
      "Colonnes restantes : ['price', 'year', 'manufacturer', 'condition', 'cylinders', 'fuel', 'odometer', 'title_status', 'transmission', 'drive', 'type', 'paint_color', 'state', 'posting_date']\n"
     ]
    }
   ],
   "source": [
    "# Supprimer les colonnes non pertinentes pour la prÃ©diction du prix\n",
    "cols_to_drop = ['id', 'url', 'region', 'region_url', 'description', 'model', \n",
    "                'VIN', 'size', 'county', 'lat', 'long', 'image_url']  # liste de colonnes Ã  Ã©liminer\n",
    "df.drop(columns=cols_to_drop, errors='ignore', inplace=True)  # errors='ignore' au cas oÃ¹ certaines colonnes n'existent pas\n",
    "\n",
    "print(\"Dimensions aprÃ¨s suppression de colonnes inutiles :\", df.shape)\n",
    "print(\"Colonnes restantes :\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion des valeurs manquantes et extraction de la date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons rÃ©duit le dataset aux **colonnes d'intÃ©rÃªt**, traitons les **valeurs manquantes**.\r\n",
    "\r\n",
    "Il est frÃ©quent dâ€™avoir des donnÃ©es incomplÃ¨tes dans ce type de jeu de donnÃ©es.  \r\n",
    "Par exemple, un vendeur peut ne pas avoir renseignÃ© :\r\n",
    "\r\n",
    "- le **kilomÃ©trage** (`odometer`)\r\n",
    "- lâ€™**Ã©tat du vÃ©hicule** (`condition`)\r\n",
    "- ou dâ€™autres informations importantes\r\n",
    "\r\n",
    "Pour **simplifier lâ€™analyse**, nous allons **supprimer les enregistrements** contenant des valeurs manquantes dans les colonnes retenues.\r\n",
    "\r\n",
    "Cette mÃ©thode peut entraÃ®ner une **rÃ©duction du nombre dâ€™exemples**,  \r\n",
    "mais ce nâ€™est **pas problÃ©matique ici**, car le dataset initial est trÃ¨s volumineux.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Transformation de la date `posting_date`\r\n",
    "\r\n",
    "La colonne `posting_date` est Ã  lâ€™origine une chaÃ®ne de caractÃ¨res (`string`), que nous allons :\r\n",
    "\r\n",
    "1. **Convertir au format `datetime`**\r\n",
    "2. Extraire les **informations temporelles** suivantes :\r\n",
    "   - `year_posted` : **annÃ©e** de publication (ex : 2018, 2019â€¦)\r\n",
    "   - `month_posted` : **mois** de publication (1 Ã  12)\r\n",
    "   - `weekday_posted` : **jour de la semaine** (0 = lundi, ..., 6 = dimanche)\r\n",
    "\r\n",
    "Ces nouvelles variables peuvent **capter des effets temporels**, comme :\r\n",
    "- des **variations de prix au fil des annÃ©es**\r\n",
    "- une **diffÃ©rence de comportement** entre les publications en semaine et en week-end\r\n",
    "\r\n",
    "Une fois ces informations extraites, la colonne brute `posting_date` ne sera **plus utile**,  \r\n",
    "elle sera donc **supprimÃ©e**.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Filtrage des outliers sur `price`\r\n",
    "\r\n",
    "On Ã©limine les annonces dont le **prix est aberrant**, en ne gardant que les vÃ©hicules dont le prix est :\r\n",
    "\r\n",
    "- **â‰¥ 100 â‚¬**\r\n",
    "- **â‰¤ 250 000 â‚¬**\r\n",
    "\r\n",
    "Ces bornes sont arbitraires, mais permettent de :\r\n",
    "- supprimer les annonces Ã  **prix nul ou trop faible**, souvent des **erreurs** ou annonces tests\r\n",
    "- exclure les **vÃ©hicules trÃ¨s luxueux** ou **mal saisis**, qui pourraient **fausser lâ€™entraÃ®nement**\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "Nous allons maintenant **appliquer** ces transformations dans la cellule de code suivante.ransformations dans la cellule de code suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions aprÃ¨s suppression des valeurs manquantes : (117169, 14)\n",
      "Dimensions aprÃ¨s nettoyage des dates : (117169, 14)\n",
      "Dimensions finales aprÃ¨s filtrage des outliers de prix : (111643, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>drive</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>state</th>\n",
       "      <th>year_posted</th>\n",
       "      <th>month_posted</th>\n",
       "      <th>weekday_posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>rwd</td>\n",
       "      <td>truck</td>\n",
       "      <td>black</td>\n",
       "      <td>al</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27990</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>gmc</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>68696.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>black</td>\n",
       "      <td>al</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34590</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>good</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>29499.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>silver</td>\n",
       "      <td>al</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>toyota</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>truck</td>\n",
       "      <td>grey</td>\n",
       "      <td>al</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29990</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>good</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>17302.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>red</td>\n",
       "      <td>al</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price    year manufacturer  condition    cylinders fuel  odometer  \\\n",
       "0  15000  2013.0         ford  excellent  6 cylinders  gas  128000.0   \n",
       "1  27990  2012.0          gmc       good  8 cylinders  gas   68696.0   \n",
       "2  34590  2016.0    chevrolet       good  6 cylinders  gas   29499.0   \n",
       "3  35000  2019.0       toyota  excellent  6 cylinders  gas   43000.0   \n",
       "4  29990  2016.0    chevrolet       good  6 cylinders  gas   17302.0   \n",
       "\n",
       "  title_status transmission drive    type paint_color state  year_posted  \\\n",
       "0        clean    automatic   rwd   truck       black    al         2021   \n",
       "1        clean        other   4wd  pickup       black    al         2021   \n",
       "2        clean        other   4wd  pickup      silver    al         2021   \n",
       "3        clean    automatic   4wd   truck        grey    al         2021   \n",
       "4        clean        other   4wd  pickup         red    al         2021   \n",
       "\n",
       "   month_posted  weekday_posted  \n",
       "0             5               0  \n",
       "1             5               0  \n",
       "2             5               0  \n",
       "3             5               0  \n",
       "4             5               0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supprimer les lignes avec des valeurs manquantes (NaN) dans les colonnes restantes\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"Dimensions aprÃ¨s suppression des valeurs manquantes :\", df.shape)\n",
    "\n",
    "# Conversion de posting_date en objet datetime (en UTC pour gÃ©rer les fuseaux horaires si prÃ©sents)\n",
    "df['posting_date'] = pd.to_datetime(df['posting_date'], errors='coerce', utc=True)\n",
    "\n",
    "# Supprimer les lignes oÃ¹ la conversion de date a Ã©chouÃ© (posting_date non parseable)\n",
    "df = df[df['posting_date'].notna()]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"Dimensions aprÃ¨s nettoyage des dates :\", df.shape)\n",
    "\n",
    "# Extraire l'annÃ©e, le mois et le jour de la semaine de la date de publication\n",
    "df['year_posted']   = df['posting_date'].dt.year\n",
    "df['month_posted']  = df['posting_date'].dt.month\n",
    "df['weekday_posted']= df['posting_date'].dt.weekday  # 0 = Lundi, ..., 6 = Dimanche\n",
    "\n",
    "# Supprimer la colonne originale posting_date (on a extrait ce qu'il nous faut)\n",
    "df.drop(columns=['posting_date'], inplace=True)\n",
    "\n",
    "# Filtrer les prix aberrants\n",
    "df = df[(df['price'] > 100) & (df['price'] < 250000)]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"Dimensions finales aprÃ¨s filtrage des outliers de prix :\", df.shape)\n",
    "\n",
    "# Un aperÃ§u des donnÃ©es aprÃ¨s nettoyage\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ã€ ce stade, nous avons un **DataFrame `df` propre**, contenant uniquement les **colonnes utiles** et **sans valeurs manquantes**.\r\n",
    "\r\n",
    "Les colonnes prÃ©sentes sont les suivantes :\r\n",
    "\r\n",
    "- `price` (**cible Ã  prÃ©dire**)\r\n",
    "- `year`, `manufacturer`, `condition`, `cylinders`, `fuel`, `odometer`, `transmission`, `drive`, `type`, `paint_color`, `state`, `title_status`\r\n",
    "- `year_posted`, `month_posted`, `weekday_posted` (**informations extraites de `posting_date`**)\r\n",
    "\r\n",
    "---\n",
    "VÃ©rifions la liste finale des colonnes et quelques statistiques de base pour se faire une idÃ©e :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes finales disponibles : ['price', 'year', 'manufacturer', 'condition', 'cylinders', 'fuel', 'odometer', 'title_status', 'transmission', 'drive', 'type', 'paint_color', 'state', 'year_posted', 'month_posted', 'weekday_posted']\n",
      "                price           year manufacturer  condition    cylinders  \\\n",
      "count   111643.000000  111643.000000       111643     111643       111643   \n",
      "unique            NaN            NaN           42          6            8   \n",
      "top               NaN            NaN         ford  excellent  6 cylinders   \n",
      "freq              NaN            NaN        20023      48961        41384   \n",
      "mean     16133.537741    2009.243813          NaN        NaN          NaN   \n",
      "std      13337.617289       9.949786          NaN        NaN          NaN   \n",
      "min        103.000000    1900.000000          NaN        NaN          NaN   \n",
      "25%       6250.000000    2006.000000          NaN        NaN          NaN   \n",
      "50%      11850.000000    2011.000000          NaN        NaN          NaN   \n",
      "75%      23590.000000    2015.000000          NaN        NaN          NaN   \n",
      "max     195000.000000    2022.000000          NaN        NaN          NaN   \n",
      "\n",
      "          fuel      odometer title_status transmission   drive    type  \\\n",
      "count   111643  1.116430e+05       111643       111643  111643  111643   \n",
      "unique       5           NaN            6            3       3      13   \n",
      "top        gas           NaN        clean    automatic     4wd   sedan   \n",
      "freq    102268           NaN       105544        91625   46823   29749   \n",
      "mean       NaN  1.119173e+05          NaN          NaN     NaN     NaN   \n",
      "std        NaN  1.932732e+05          NaN          NaN     NaN     NaN   \n",
      "min        NaN  0.000000e+00          NaN          NaN     NaN     NaN   \n",
      "25%        NaN  5.640500e+04          NaN          NaN     NaN     NaN   \n",
      "50%        NaN  1.040000e+05          NaN          NaN     NaN     NaN   \n",
      "75%        NaN  1.490000e+05          NaN          NaN     NaN     NaN   \n",
      "max        NaN  1.000000e+07          NaN          NaN     NaN     NaN   \n",
      "\n",
      "       paint_color   state  year_posted   month_posted  weekday_posted  \n",
      "count       111643  111643     111643.0  111643.000000   111643.000000  \n",
      "unique          12      51          NaN            NaN             NaN  \n",
      "top          white      ca          NaN            NaN             NaN  \n",
      "freq         26759   12273          NaN            NaN             NaN  \n",
      "mean           NaN     NaN       2021.0       4.287577        2.720350  \n",
      "std            NaN     NaN          0.0       0.452635        2.020377  \n",
      "min            NaN     NaN       2021.0       4.000000        0.000000  \n",
      "25%            NaN     NaN       2021.0       4.000000        1.000000  \n",
      "50%            NaN     NaN       2021.0       4.000000        3.000000  \n",
      "75%            NaN     NaN       2021.0       5.000000        4.000000  \n",
      "max            NaN     NaN       2021.0       5.000000        6.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"Colonnes finales disponibles :\", df.columns.tolist())\n",
    "print(df.describe(include='all'))  # statistiques rapides, inclut les numÃ©riques par dÃ©faut\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(La sortie ci-dessus donne des informations statistiques : par exemple le prix moyen, le kilomÃ©trage moyen, etc., ainsi que le nombre de catÃ©gories uniques pour les colonnes non numÃ©riques si on prÃ©cise include='all'.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage des variables catÃ©gorielles et normalisation des numÃ©riques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifions maintenant quelles sont les colonnes **catÃ©gorielles** et lesquelles sont **numÃ©riques**, afin de les traiter correctement.\r\n",
    "\r\n",
    "- **Colonnes numÃ©riques** :  \r\n",
    "  `year`, `odometer`, `year_posted`, `month_posted`, `weekday_posted`  \r\n",
    "  Ce sont des variables continues ayant une signification quantitative.\r\n",
    "\r\n",
    "- **Colonnes catÃ©gorielles** :  \r\n",
    "  `manufacturer`, `condition`, `cylinders`, `fuel`, `transmission`, `drive`, `type`, `paint_color`, `state`, `title_status`  \r\n",
    "  Ces colonnes sont typiquement de type *object* (texte) dans le DataFrame.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "Nous allons appliquer un **One-Hot Encoding** sur toutes ces variables catÃ©gorielles Ã  lâ€™aide de `pd.get_dummies`.  \r\n",
    "Cela va crÃ©er une colonne binaire (0/1) pour chaque catÃ©gorie possible de chaque variable.  \r\n",
    "Par exemple :  \r\n",
    "â†’ La colonne `fuel` donnera `fuel_gas`, `fuel_diesel`, `fuel_elric`, etc.\r\n",
    "\r\n",
    "ğŸ’¡ **Remarque importante** :  \r\n",
    "- Nous ne ferons **pas** `drop_first=True` pour ne pas introduire de biais arbitraire (rÃ©fÃ©rence implicite).  \r\n",
    "- Cela entraÃ®nera une **augmentation du nombre de colonnes**, mais les rÃ©seaux de neurones peuvent le gÃ©rer.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "Une fois cela fait, nous **standardiserons les variables numÃ©riques** (soustraction de la moyenne et division par lâ€™Ã©cart-type).  \r\n",
    "Mais cette Ã©tape sera rÃ©alisÃ©e **aprÃ¨s le split train/val/test** pour Ã©viter toute **fuite de donnÃ©es**.  \r\n",
    "La normalisation se fera **uniquement** Ã  partir des statistiques du jeu d'entraÃ®nement.\r\n",
    "\r\n",
    "Enfin, pour sâ€™assurer que tous les datasets (train, val, test) ont les **mÃªmes colonnes dummies**,  \r\n",
    "nous appliquerons `get_dummies` **sur lâ€™ensemble complet** du DataFrame dÃ¨s maintenant.  \r\n",
    "Ainsi, une catÃ©gorie prÃ©sente uniquement dans le test (par exemple) aura une colonne dÃ©jÃ  prÃªte (elle sera simplement Ã  0 ailleurs).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "ProcÃ©dons donc Ã  lâ€™encodage, puis Ã  la sÃ©paration des donnÃ©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de features aprÃ¨s encodage : 154\n",
      "Quelques-unes des colonnes encodÃ©es : ['year', 'odometer', 'year_posted', 'month_posted', 'weekday_posted', 'manufacturer_acura', 'manufacturer_alfa-romeo', 'manufacturer_aston-martin', 'manufacturer_audi', 'manufacturer_bmw', 'manufacturer_buick', 'manufacturer_cadillac', 'manufacturer_chevrolet', 'manufacturer_chrysler', 'manufacturer_datsun', 'manufacturer_dodge', 'manufacturer_ferrari', 'manufacturer_fiat', 'manufacturer_ford', 'manufacturer_gmc']\n"
     ]
    }
   ],
   "source": [
    "# SÃ©parer la cible des features\n",
    "y = df['price'].astype('float32')  # le prix, converti en float32 (type appropriÃ© pour Keras)\n",
    "X = df.drop(columns=['price'])\n",
    "\n",
    "# Identifier les colonnes catÃ©gorielles et numÃ©riques\n",
    "cat_cols = ['manufacturer', 'condition', 'cylinders', 'fuel', \n",
    "            'transmission', 'drive', 'type', 'paint_color', \n",
    "            'state', 'title_status']\n",
    "num_cols = ['year', 'odometer', 'year_posted', 'month_posted', 'weekday_posted']\n",
    "\n",
    "# Encodage one-hot des variables catÃ©gorielles\n",
    "X_dummies = pd.get_dummies(X[cat_cols], prefix_sep='_', drop_first=False)\n",
    "# ConcatÃ©ner avec les colonnes numÃ©riques non encodÃ©es\n",
    "X_numeric = X[num_cols].astype('float32')\n",
    "X_encoded = pd.concat([X_numeric, X_dummies], axis=1)\n",
    "\n",
    "print(\"Nombre de features aprÃ¨s encodage :\", X_encoded.shape[1])\n",
    "print(\"Quelques-unes des colonnes encodÃ©es :\", X_encoded.columns[:20].tolist())  # aperÃ§u des premiÃ¨res colonnes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailles : X_train = (78194, 154) | X_val = (16702, 154) | X_test = (16747, 154)\n"
     ]
    }
   ],
   "source": [
    "# DÃ©coupage en ensembles d'entraÃ®nement, validation et test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tout d'abord, sÃ©parer un ensemble de test (par ex 15% des donnÃ©es)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_encoded, y, test_size=0.15, random_state=42)\n",
    "# Ensuite, sÃ©parer le reste en train et validation (environ 15% validation sur le total, donc environ 0.15/0.85 â‰ˆ 17.6% de X_temp)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42)\n",
    "\n",
    "print(\"Tailles : X_train =\", X_train.shape, \"| X_val =\", X_val.shape, \"| X_test =\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, appliquons la normalisation (standardisation) aux colonnes numÃ©riques de nos matrices d'entrÃ©e : on ajuste uniquement sur X_train puis on transforme X_val et X_test en utilisant les paramÃ¨tres calculÃ©s sur X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyennes des colonnes numÃ©riques (train) aprÃ¨s standardisation: [0.0, 0.0, 0.0, -0.0, 0.0]\n",
      "Ã‰carts-types des colonnes numÃ©riques (train) aprÃ¨s standardisation: [1.0, 1.0, 0.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Normalisation (StandardScaler) des features numÃ©riques\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Ajuster le scaler sur les donnÃ©es d'entraÃ®nement (colonnes numÃ©riques uniquement)\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "# Appliquer la transformation aux jeux de validation et de test\n",
    "X_val[num_cols] = scaler.transform(X_val[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# VÃ©rifier que la normalisation a Ã©tÃ© effectuÃ©e (moyenne ~0, Ã©cart-type ~1 sur train)\n",
    "print(\"Moyennes des colonnes numÃ©riques (train) aprÃ¨s standardisation:\", X_train[num_cols].mean().round(3).tolist())\n",
    "print(\"Ã‰carts-types des colonnes numÃ©riques (train) aprÃ¨s standardisation:\", X_train[num_cols].std().round(3).tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, convertissons nos matrices de features et vecteurs cibles en formats appropriÃ©s pour Keras (numpy arrays). Pandas DataFrame peut Ãªtre acceptÃ© directement, mais pour sÃ©curitÃ© on utilisera .values pour obtenir des np.ndarray. On s'assure aussi que nos cibles y_train, y_val, y_test sont bien des vecteurs numpy de type float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format des arrays final : (78194, 154) (78194,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_np = X_train.values.astype('float32')\n",
    "X_val_np   = X_val.values.astype('float32')\n",
    "X_test_np  = X_test.values.astype('float32')\n",
    "\n",
    "y_train_np = y_train.values.astype('float32')\n",
    "y_val_np   = y_val.values.astype('float32')\n",
    "y_test_np  = y_test.values.astype('float32')\n",
    "\n",
    "print(\"Format des arrays final :\", X_train_np.shape, y_train_np.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos donnÃ©es sont prÃªtes. Nous avons maintenant :\n",
    "X_train_np (matrice des features d'entraÃ®nement) et y_train_np (valeurs cibles correspondantes),\n",
    "X_val_np et y_val_np,\n",
    "X_test_np et y_test_np.\n",
    "Le tout est normalisÃ© et encodÃ©, prÃªt Ã  Ãªtre ingÃ©rÃ© par un rÃ©seau de neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DÃ©finition du rÃ©seau de neurones pour la rÃ©gression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant dÃ©finir l'architecture de notre **rÃ©seau de neurones**.  \r\n",
    "Il s'agira dâ€™un **rÃ©seau feedforward** simple (rÃ©seau Ã  propagation avant), structurÃ© comme suit :\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "**Structure du modÃ¨le :**\r\n",
    "\r\n",
    "- **Couche d'entrÃ©e**  \r\n",
    "  Attend un vecteur de dimension Ã©gale au nombre de variables explicatives aprÃ¨s encodage.  \r\n",
    "  Elle sera dÃ©finie implicitement via la premiÃ¨re couche `Dense` avec `input_shape`.\r\n",
    "\r\n",
    "- **1Ã¨re couche cachÃ©e `Dense`**  \r\n",
    "  - 64 neurones  \r\n",
    "  - Activation : `ReLU`  \r\n",
    "  Ce choix permet de modÃ©liser des relations non-linÃ©aires sans complexifier Ã  lâ€™excÃ¨s le modÃ¨le.  \r\n",
    "  L'activation ReLU est standard pour sa simplicitÃ©, son efficacitÃ© et lâ€™absence de problÃ¨me de vanishing gradient.\r\n",
    "\r\n",
    "- **2Ã¨me couche cachÃ©e `Dense`**  \r\n",
    "  - 32 neurones  \r\n",
    "  - Activation : `ReLU`  \r\n",
    "  Une taille plus rÃ©duite sert de **rÃ©gularisation implicite**, limitant la complexitÃ© tout en gardant une bonne expressivitÃ©.\r\n",
    "\r\n",
    "- **Couche de sortie `Dense`**  \r\n",
    "  - 1 neurone  \r\n",
    "  - Activation : `linÃ©aire`  \r\n",
    "  AppropriÃ©e pour la rÃ©gression : elle permet de prÃ©dire une valeur rÃ©elle (le prix).  \r\n",
    "  On ne contraint pas explicitement Ã  des valeurs positives, ce qui reste acceptable avec des donnÃ©es bien normalisÃ©es.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "**Fonction de perte (loss)** :  \r\n",
    "Nous utiliserons la **MSE (Mean Squared Error)**, courante en rÃ©gression.  \r\n",
    "Elle est diffÃ©rentiable, sensible aux gros Ã©carts, et permet au modÃ¨le de mieux gÃ©rer les erreurs importantes.  \r\n",
    "\r\n",
    "**MÃ©trique de suivi** :  \r\n",
    "Nous suivrons Ã©galement la **MAE (Mean Absolute Error)** Ã  chaque Ã©poque.  \r\n",
    "Elle est plus facile Ã  interprÃ©ter (valeur moyenne absolue de lâ€™erreur en euros, par exemple).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "**Objectif expÃ©rimental** :  \r\n",
    "Nous allons comparer plusieurs **optimiseurs** (SGD, Adam, RMSprop, Adagrad)  \r\n",
    "et nous assurerons que **chaque modÃ¨le** commence avec les **mÃªmes poids initiaux**.  \r\n",
    "\r\n",
    "Pour cela :\r\n",
    "- Nous dÃ©finirons une **fonction `build_model()`** qui construit un modÃ¨le neuf.\r\n",
    "- Nous utiliserons `tf.random.set_seed()` pour fixer la graine alÃ©atoire Ã  chaque appel, assurant une initialisation identique des poids.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "Nous utiliserons **TensorFlow (Keras)** pour lâ€™implÃ©mentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,920</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m9,920\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,033</span> (47.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,033\u001b[0m (47.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,033</span> (47.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,033\u001b[0m (47.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model():\n",
    "    # Fixer la graine pour avoir la mÃªme initialisation Ã  chaque appel\n",
    "    tf.random.set_seed(42)\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(X_train_np.shape[1],)),  # Utiliser une couche Input explicite\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Tester la construction du modÃ¨le\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit dans le rÃ©sumÃ© que le rÃ©seau comporte un certain nombre de paramÃ¨tres :\n",
    "Pour la couche Dense de 64 neurones en entrÃ©e, avec n features en entrÃ©e, il y a 64 * n + 64 paramÃ¨tres (poids + biais).\n",
    "Pour la couche Dense de 32 neurones suivante, 32 * 64 + 32 paramÃ¨tres.\n",
    "Pour la couche de sortie 1 neurone, 1 * 32 + 1 paramÃ¨tres.\n",
    "Cela donne un total (affichÃ© par model.summary()) qu'on peut noter. Maintenant, nous allons compiler le modÃ¨le avec la configuration d'apprentissage. Nous ne le faisons pas encore car nous allons le compiler diffÃ©remment pour chaque optimiseur testÃ©."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EntraÃ®nement du modÃ¨le avec diffÃ©rents optimiseurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant entraÃ®ner le **rÃ©seau dÃ©fini prÃ©cÃ©demment** avec plusieurs **algorithmes d'optimisation**, puis **comparer leurs performances**.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### Optimiseurs comparÃ©s :\r\n",
    "\r\n",
    "- **SGD (Stochastic Gradient Descent)**  \r\n",
    "  Descente de gradient stochastique classique.  \r\n",
    "  UtilisÃ© ici **sans momentum**, avec un learning rate de **0.01**.  \r\n",
    "  Sert de **rÃ©fÃ©rence \"brute\"** face aux mÃ©thodes adaptatives.\r\n",
    "\r\n",
    "- **Adam (Adaptive Moment Estimation)**  \r\n",
    "  MÃ©thode adaptative trÃ¨s populaire.  \r\n",
    "  Combine moyenne des gradients et moyenne des gradients au carrÃ©.  \r\n",
    "  Learning rate typique : **0.001**.  \r\n",
    "  Reconnue pour une **convergence rapide en dÃ©but dâ€™entraÃ®nement**.\r\n",
    "\r\n",
    "- **RMSprop**  \r\n",
    "  MÃ©thode adaptative qui maintient une moyenne glissante des **gradients au carrÃ©**.  \r\n",
    "  Learning rate : **0.001**.  \r\n",
    "  Efficace pour les **rÃ©seaux profonds** ou les gradients instables.\r\n",
    "\r\n",
    "- **Adagrad**  \r\n",
    "  MÃ©thode adaptative plus ancienne.  \r\n",
    "  Accumule les gradients pour **rÃ©duire progressivement le learning rate**.  \r\n",
    "  Learning rate par dÃ©faut : **0.001**.  \r\n",
    "  Rapide au dÃ©but mais peut **ralentir fortement sur le long terme**.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "> Nous nous concentrerons sur **ces quatre mÃ©thodes**.  \r\n",
    "> Dâ€™autres variantes (Adadelta, Adamax, SGD avec momentum...) peuvent Ãªtre testÃ©es, mais ne seront pas analysÃ©es ici.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "#### Pour chaque optimiseur, nous suivrons le mÃªme protocole :\r\n",
    "\r\n",
    "1. **Construction dâ€™un nouveau modÃ¨le**  \r\n",
    "   â†’ GrÃ¢ce Ã  `build_model()` avec **poids initiaux identiques** (graine fixÃ©e).\r\n",
    "\r\n",
    "2. **Compilation**  \r\n",
    "   â†’ Optimiseur choisi + perte **MSE** + mÃ©trique **MAE**.\r\n",
    "\r\n",
    "3. **EntraÃ®nement**  \r\n",
    "   â†’ Sur **100 Ã©poques** (valeur identique pour tous).  \r\n",
    "   â†’ Suivi de la **MAE de validation** (`validation_data=(X_val_np, y_val_np)`).\r\n",
    "\r\n",
    "4. **Mesure du temps total d'entraÃ®nement**.\r\n",
    "\r\n",
    "5. **Enregistrement de lâ€™historique**  \r\n",
    "   â†’ Pour comparer les **courbes de perte et MAE**.\r\n",
    "\r\n",
    "6. **Ã‰valuation finale**  \r\n",
    "   â†’ Sur le **jeu de test** : pour vÃ©rifier la **gÃ©nÃ©ralisation** du modÃ¨le.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "AprÃ¨s chaque entraÃ®nement, nous commenterons :\r\n",
    "- **La vitesse de convergence** (via la courbe de validation MAE)\r\n",
    "- **La performance finale** (val/test MAE)\r\n",
    "\r\n",
    "â„¹ï¸ Lâ€™entraÃ®nement sur lâ€™ensemble des donnÃ©es peut **prendre plusieurs minutes**, selon la machine et la complexitÃ© du modÃ¨le."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EntraÃ®nement avec l'optimiseur SGD (Descente de Gradient Stochastique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CommenÃ§ons par l'optimiseur SGD classique. Nous nous attendons Ã  une convergence plus lente, car SGD utilise un taux d'apprentissage fixe (0.001 par dÃ©faut) et n'adapte pas les pas de gradient individuellement. Sans momentum, SGD peut nÃ©cessiter de nombreuses Ã©poques pour approcher le minimum. Observons comment la MAE diminue au fil des itÃ©rations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š RÃ©sultats - Optimiseur SGD\n",
      "DurÃ©e d'entraÃ®nement : 435.3 secondes\n",
      "Train : MAE = 3646.99 (22.7%), RMSE = 60.39 (0.4%)\n",
      "Val   : MAE = 3795.98 (23.6%), RMSE = 61.61 (0.4%)\n",
      "Test  : MAE = 3675.78 (22.9%), RMSE = 60.63 (0.4%)\n"
     ]
    }
   ],
   "source": [
    "# EntraÃ®nement du modÃ¨le avec SGD\n",
    "import time\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "model_sgd = build_model()\n",
    "optimizer_sgd = keras.optimizers.SGD(learning_rate=0.001, clipnorm=1.0)\n",
    "\n",
    "model_sgd.compile(optimizer=optimizer_sgd, loss='mae', metrics=['mae'])\n",
    "\n",
    "start_time = time.time()\n",
    "history_sgd = model_sgd.fit(\n",
    "    X_train_np, y_train_np,\n",
    "    epochs=100, batch_size=32,\n",
    "    validation_data=(X_val_np, y_val_np),\n",
    "    verbose=0\n",
    ")\n",
    "elapsed_sgd = time.time() - start_time\n",
    "\n",
    "# Ã‰valuation\n",
    "train_mse, train_mae = model_sgd.evaluate(X_train_np, y_train_np, verbose=0)\n",
    "val_mse, val_mae = model_sgd.evaluate(X_val_np, y_val_np, verbose=0)\n",
    "test_mse, test_mae = model_sgd.evaluate(X_test_np, y_test_np, verbose=0)\n",
    "\n",
    "# RMSE\n",
    "train_rmse = sqrt(train_mse)\n",
    "val_rmse = sqrt(val_mse)\n",
    "test_rmse = sqrt(test_mse)\n",
    "\n",
    "# Moyenne du prix rÃ©el (pour avoir des %)\n",
    "mean_price = np.mean(y_test_np)\n",
    "\n",
    "# Affichage clair et interprÃ©table\n",
    "print(\"\\nğŸ“Š RÃ©sultats - Optimiseur SGD\")\n",
    "print(f\"DurÃ©e d'entraÃ®nement : {elapsed_sgd:.1f} secondes\")\n",
    "print(f\"Train : MAE = {train_mae:.2f} ({train_mae / mean_price * 100:.1f}%), RMSE = {train_rmse:.2f} ({train_rmse / mean_price * 100:.1f}%)\")\n",
    "print(f\"Val   : MAE = {val_mae:.2f} ({val_mae / mean_price * 100:.1f}%), RMSE = {val_rmse:.2f} ({val_rmse / mean_price * 100:.1f}%)\")\n",
    "print(f\"Test  : MAE = {test_mae:.2f} ({test_mae / mean_price * 100:.1f}%), RMSE = {test_rmse:.2f} ({test_rmse / mean_price * 100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InterprÃ©tation SGD : Avec SGD, la descente est progressive. Sur les 100 Ã©poques, on s'attend Ã  voir la MAE de validation diminuer lentement. Le rÃ©sultat imprimÃ© donne la MAE finale : on peut constater par exemple que la MAE entraÃ®nement est plus basse que la MAE validation, signe d'un lÃ©ger sur-apprentissage ou simplement que le modÃ¨le n'a pas encore atteint son minimum global sur val. Le temps d'entraÃ®nement est notre rÃ©fÃ©rence de base (par exemple X secondes). Globalement, SGD semble nÃ©cessiter davantage d'Ã©poques pour atteindre une erreur faible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EntraÃ®nement avec l'optimiseur Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EntraÃ®nons maintenant le mÃªme modÃ¨le avec Adam, qui devrait converger plus rapidement grÃ¢ce Ã  l'adaptation du taux de learning pour chaque paramÃ¨tre. On utilise les paramÃ¨tres par dÃ©faut (lr=0.001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# EntraÃ®nement avec Adam \n",
    "model_adam = build_model()\n",
    "optimizer_adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_adam.compile(optimizer=optimizer_adam, loss='mse', metrics=['mae'])\n",
    "\n",
    "start_time = time.time()\n",
    "history_adam = model_adam.fit(X_train_np, y_train_np, epochs=100, batch_size=32, \n",
    "                               validation_data=(X_val_np, y_val_np), verbose=0)\n",
    "elapsed_adam = time.time() - start_time\n",
    "\n",
    "# Ã‰valuation\n",
    "train_mse, train_mae = model_adam.evaluate(X_train_np, y_train_np, verbose=0)\n",
    "val_mse, val_mae = model_adam.evaluate(X_val_np, y_val_np, verbose=0)\n",
    "test_mse, test_mae = model_adam.evaluate(X_test_np, y_test_np, verbose=0)\n",
    "baseline_mae = test_mae  # Pour les comparaisons futures\n",
    "\n",
    "# RMSE\n",
    "train_rmse = sqrt(train_mse)\n",
    "val_rmse = sqrt(val_mse)\n",
    "test_rmse = sqrt(test_mse)\n",
    "\n",
    "print(\"\\nRÃ©sultats - Optimiseur Adam\")\n",
    "print(f\"DurÃ©e d'entraÃ®nement : {elapsed_adam:.1f} secondes\")\n",
    "print(f\"Train : MAE = {train_mae:.2f} ({train_mae / mean_price * 100:.1f}%), RMSE = {train_rmse:.2f} ({train_rmse / mean_price * 100:.1f}%)\")\n",
    "print(f\"Val   : MAE = {val_mae:.2f} ({val_mae / mean_price * 100:.1f}%), RMSE = {val_rmse:.2f} ({val_rmse / mean_price * 100:.1f}%)\")\n",
    "print(f\"Test  : MAE = {test_mae:.2f} ({test_mae / mean_price * 100:.1f}%), RMSE = {test_rmse:.2f} ({test_rmse / mean_price * 100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InterprÃ©tation Adam : Comme attendu, Adam converge beaucoup plus vite. La MAE de validation baisse significativement plus rapidement dans les premiÃ¨res Ã©poques comparÃ© Ã  SGD. Au bout de 100 Ã©poques, Adam atteint gÃ©nÃ©ralement une MAE plus faible que SGD. Par exemple, on peut voir que la MAE validation est infÃ©rieure Ã  celle obtenue avec SGD (et assez proche de la MAE train, signe que le modÃ¨le gÃ©nÃ©ralise bien). Le temps d'exÃ©cution total n'est pas Ã©normÃ©ment plus Ã©levÃ© que pour SGD (Adam calcule plus de choses par itÃ©ration, mais ici la diffÃ©rence reste faible). Adam se distingue donc par son efficacitÃ© Ã  rÃ©duire l'erreur rapidement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EntraÃ®nement avec RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons maintenant RMSprop, un optimiseur adaptatif proche d'Adam (il n'utilise pas la composante de momentum du gradient moyen, seulement le carrÃ© moyen). On s'attend Ã  une performance de convergence Ã©galement rapide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EntraÃ®nement avec RMSprop\n",
    "model_rms = build_model()\n",
    "optimizer_rms = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "model_rms.compile(optimizer=optimizer_rms, loss='mse', metrics=['mae'])\n",
    "\n",
    "start_time = time.time()\n",
    "history_rms = model_rms.fit(X_train_np, y_train_np, epochs=100, batch_size=32, \n",
    "                             validation_data=(X_val_np, y_val_np), verbose=0)\n",
    "elapsed_rms = time.time() - start_time\n",
    "\n",
    "# Ã‰valuation\n",
    "train_mse, train_mae = model_rms.evaluate(X_train_np, y_train_np, verbose=0)\n",
    "val_mse, val_mae = model_rms.evaluate(X_val_np, y_val_np, verbose=0)\n",
    "test_mse, test_mae = model_rms.evaluate(X_test_np, y_test_np, verbose=0)\n",
    "\n",
    "train_rmse = sqrt(train_mse)\n",
    "val_rmse = sqrt(val_mse)\n",
    "test_rmse = sqrt(test_mse)\n",
    "\n",
    "print(\"\\nğŸ“Š RÃ©sultats - Optimiseur RMSprop\")\n",
    "print(f\"DurÃ©e d'entraÃ®nement : {elapsed_rms:.1f} secondes\")\n",
    "print(f\"Train : MAE = {train_mae:.2f} ({train_mae / mean_price * 100:.1f}%), RMSE = {train_rmse:.2f} ({train_rmse / mean_price * 100:.1f}%)\")\n",
    "print(f\"Val   : MAE = {val_mae:.2f} ({val_mae / mean_price * 100:.1f}%), RMSE = {val_rmse:.2f} ({val_rmse / mean_price * 100:.1f}%)\")\n",
    "print(f\"Test  : MAE = {test_mae:.2f} ({test_mae / mean_price * 100:.1f}%), RMSE = {test_rmse:.2f} ({test_rmse / mean_price * 100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InterprÃ©tation RMSprop : RMSprop affiche une convergence similaire Ã  Adam dans ce cas. Souvent, on observe que RMSprop atteint presque les mÃªmes performances qu'Adam en validation, peut-Ãªtre avec une courbe un peu moins lisse. La MAE finale validation et test sont comparables Ã  celles d'Adam (parfois lÃ©gÃ¨rement supÃ©rieures ou infÃ©rieures selon les cas, mais de mÃªme ordre). Le temps d'entraÃ®nement est du mÃªme ordre de grandeur. En rÃ©sumÃ©, RMSprop est trÃ¨s efficace sur ce problÃ¨me, proche d'Adam en termes de vitesse de convergence et de performance atteinte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EntraÃ®nement avec Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, testons Adagrad. C'est un optimiseur adaptatif qui diminue progressivement le learning rate effectif Ã  mesure que les gradients s'accumulent. Il peut Ãªtre trÃ¨s rapide initialement mais a tendance Ã  stagner sur le long terme une fois qu'il a beaucoup rÃ©duit ses pas de gradient.\n",
    "python\n",
    "Copier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EntraÃ®nement avec Adagrad\n",
    "model_ada = build_model()\n",
    "optimizer_ada = keras.optimizers.Adagrad(learning_rate=0.001)\n",
    "model_ada.compile(optimizer=optimizer_ada, loss='mse', metrics=['mae'])\n",
    "\n",
    "start_time = time.time()\n",
    "history_ada = model_ada.fit(X_train_np, y_train_np, epochs=100, batch_size=32, \n",
    "                             validation_data=(X_val_np, y_val_np), verbose=0)\n",
    "elapsed_ada = time.time() - start_time\n",
    "\n",
    "# Ã‰valuation\n",
    "train_mse, train_mae = model_ada.evaluate(X_train_np, y_train_np, verbose=0)\n",
    "val_mse, val_mae = model_ada.evaluate(X_val_np, y_val_np, verbose=0)\n",
    "test_mse, test_mae = model_ada.evaluate(X_test_np, y_test_np, verbose=0)\n",
    "\n",
    "train_rmse = sqrt(train_mse)\n",
    "val_rmse = sqrt(val_mse)\n",
    "test_rmse = sqrt(test_mse)\n",
    "\n",
    "print(\"\\nğŸ“Š RÃ©sultats - Optimiseur Adagrad\")\n",
    "print(f\"DurÃ©e d'entraÃ®nement : {elapsed_ada:.1f} secondes\")\n",
    "print(f\"Train : MAE = {train_mae:.2f} ({train_mae / mean_price * 100:.1f}%), RMSE = {train_rmse:.2f} ({train_rmse / mean_price * 100:.1f}%)\")\n",
    "print(f\"Val   : MAE = {val_mae:.2f} ({val_mae / mean_price * 100:.1f}%), RMSE = {val_rmse:.2f} ({val_rmse / mean_price * 100:.1f}%)\")\n",
    "print(f\"Test  : MAE = {test_mae:.2f} ({test_mae / mean_price * 100:.1f}%), RMSE = {test_rmse:.2f} ({test_rmse / mean_price * 100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "InterprÃ©tation Adagrad : On observe gÃ©nÃ©ralement qu'Adagrad commence bien (premiÃ¨res Ã©poques efficaces) mais qu'il atteint assez vite un palier. En 100 Ã©poques, il est possible que la MAE de validation d'Adagrad soit un peu supÃ©rieure Ã  celle d'Adam/RMSprop, signe qu'il a cessÃ© d'apprendre de maniÃ¨re agressive. La MAE entraÃ®nement peut rester un peu plus Ã©levÃ©e que pour les autres (signe que l'optimiseur a ralenti), et la MAE validation/test suit le mÃªme trend. Le temps d'entraÃ®nement est similaire, la diffÃ©rence rÃ©sidant dans la progression de l'erreur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison globale des optimiseurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que chaque optimiseur a Ã©tÃ© testÃ©, comparons visuellement leurs courbes de convergence (MAE et loss MSE au fil des Ã©poques)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Courbes de MAE de validation pour chaque optimiseur\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history_sgd.history['val_mae'], label='SGD')\n",
    "plt.plot(history_adam.history['val_mae'], label='Adam')\n",
    "plt.plot(history_rms.history['val_mae'], label='RMSprop')\n",
    "plt.plot(history_ada.history['val_mae'], label='Adagrad')\n",
    "plt.title(\"MAE de validation vs Ã©poques (par optimiseur)\")\n",
    "plt.xlabel(\"Ã‰poques\")\n",
    "plt.ylabel(\"MAE (validation)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Courbes de loss (MSE) de validation pour chaque optimiseur\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history_sgd.history['val_loss'], label='SGD')\n",
    "plt.plot(history_adam.history['val_loss'], label='Adam')\n",
    "plt.plot(history_rms.history['val_loss'], label='RMSprop')\n",
    "plt.plot(history_ada.history['val_loss'], label='Adagrad')\n",
    "plt.title(\"Loss (MSE) de validation vs Ã©poques (par optimiseur)\")\n",
    "plt.xlabel(\"Ã‰poques\")\n",
    "plt.ylabel(\"MSE (validation)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sur la premiÃ¨re figure (MAE validation), on voit nettement que **Adam** et **RMSprop** descendent beaucoup plus rapidement que **SGD** dans les premiÃ¨res Ã©poques.*\r\n",
    "\r\n",
    "- Adam atteint une faible MAE dÃ¨s environ **20 Ã  30 Ã©poques**, puis se stabilise.\r\n",
    "- La courbe de SGD baisse plus lentement et **nâ€™a pas encore atteint le niveau dâ€™Adam Ã  la 100áµ‰ Ã©poque**.\r\n",
    "- RMSprop suit une trajectoire proche dâ€™Adam, lÃ©gÃ¨rement en retrait vers la fin.\r\n",
    "- Adagrad baisse vite au dÃ©but, parfois presque aussi vite quâ€™Adam, mais **se stabilise plus haut**, ce qui est cohÃ©rent avec la nature de son taux dâ€™apprentissage qui diminue avec le temps.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "*La deuxiÃ¨me figure (loss MSE) montre un comportement similaire :*\r\n",
    "\r\n",
    "- Adam et RMSprop **diminuent fortement la loss** initialement, puis stagnent.\r\n",
    "- SGD baisse de faÃ§on **plus linÃ©aire**, sans atteindre le niveau des autres.\r\n",
    "- Adagrad diminue rapidement sa loss puis la courbe devient quasiment plate en fin d'entraÃ®nement.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "# Performances finales\r\n",
    "\r\n",
    "*En rÃ©sumÃ© :*\r\n",
    "\r\n",
    "- **Adam** et **RMSprop** atteignent les **meilleures MAE de validation**.\r\n",
    "- **Adagrad** est lÃ©gÃ¨rement en dessous.\r\n",
    "- **SGD** est **le moins performant Ã  100 Ã©poques**, mais il continue de sâ€™amÃ©liorer rÃ©guliÃ¨rement.\r\n",
    "\r\n",
    "*Sur le jeu de test*, les MAE sont proches de celles obtenues en validation, ce qui signifie que **le modÃ¨le gÃ©nÃ©ralise bien**. Il nâ€™y a **pas de sur-apprentissage visible**, en partie grÃ¢ce Ã  la **taille importante du dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ã‰volution des MAE entraÃ®nement/validation par optimiseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(history_sgd.history['mae'], label='SGD - Train', linestyle='-')\n",
    "plt.plot(history_sgd.history['val_mae'], label='SGD - Val', linestyle='--')\n",
    "\n",
    "plt.plot(history_adam.history['mae'], label='Adam - Train', linestyle='-')\n",
    "plt.plot(history_adam.history['val_mae'], label='Adam - Val', linestyle='--')\n",
    "\n",
    "plt.plot(history_rms.history['mae'], label='RMSprop - Train', linestyle='-')\n",
    "plt.plot(history_rms.history['val_mae'], label='RMSprop - Val', linestyle='--')\n",
    "\n",
    "plt.plot(history_ada.history['mae'], label='Adagrad - Train', linestyle='-')\n",
    "plt.plot(history_ada.history['val_mae'], label='Adagrad - Val', linestyle='--')\n",
    "\n",
    "plt.title(\"MAE - EntraÃ®nement vs Validation pour chaque optimiseur\")\n",
    "plt.xlabel(\"Ã‰poques\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution des erreurs sur les donnÃ©es de test (prÃ©dictions - rÃ©alitÃ©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for name, model in {\n",
    "    \"SGD\": model_sgd,\n",
    "    \"Adam\": model_adam,\n",
    "    \"RMSprop\": model_rms,\n",
    "    \"Adagrad\": model_ada\n",
    "}.items():\n",
    "    y_pred = model.predict(X_test_np).flatten()\n",
    "    errors = y_test_np.flatten() - y_pred\n",
    "    sns.kdeplot(errors, label=name)\n",
    "\n",
    "plt.title(\"Distribution des erreurs de prÃ©diction (test)\")\n",
    "plt.xlabel(\"Erreur (rÃ©elle - prÃ©dite)\")\n",
    "plt.ylabel(\"DensitÃ©\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PrÃ©dictions vs Valeurs rÃ©elles (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for name, model in {\n",
    "    \"SGD\": model_sgd,\n",
    "    \"Adam\": model_adam,\n",
    "    \"RMSprop\": model_rms,\n",
    "    \"Adagrad\": model_ada\n",
    "}.items():\n",
    "    y_pred = model.predict(X_test_np).flatten()\n",
    "    plt.scatter(y_test_np, y_pred, alpha=0.3, label=name)\n",
    "\n",
    "min_val = y_test_np.min()\n",
    "max_val = y_test_np.max()\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label=\"RÃ©el = PrÃ©dit\")\n",
    "\n",
    "plt.title(\"PrÃ©dictions vs Valeurs rÃ©elles (jeu de test)\")\n",
    "plt.xlabel(\"Valeurs rÃ©elles\")\n",
    "plt.ylabel(\"PrÃ©dictions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de l'importance des caractÃ©ristiques par ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant **Ã©valuer l'importance de chaque feature** dans la prÃ©diction du prix.\r\n",
    "\r\n",
    "La mÃ©thode employÃ©e est une **analyse par ablation** :  \r\n",
    "on retire **une colonne Ã  la fois** du jeu de features et on rÃ©entraÃ®ne le modÃ¨le (en utilisant l'optimiseur **Adam**, qui a donnÃ© les meilleurs rÃ©sultats) pour observer **l'impact sur la MAE**.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "**Principe :**\r\n",
    "\r\n",
    "- Si la suppression d'une feature **provoque une forte augmentation** de la MAE finale, cela signifie que cette feature Ã©tait **importante**.\r\n",
    "- Si la suppression **n'impacte que trÃ¨s peu** la MAE, câ€™est que la feature Ã©tait **peu informative** ou **redondante\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "âš ï¸ **Remarque importante** :  \r\n",
    "Cette mÃ©thode est **coÃ»teuse en temps de calcul**, car elle nÃ©cessite :\r\n",
    "- D'entraÃ®ner **un nouveau modÃ¨le pour chaque feature supprimÃ©e**.\r\n",
    "- Avec 14 features dâ€™entrÃ©e, cela fait **14 entraÃ®nements complets** de 100 Ã©poques chacun.\r\n",
    "\r\n",
    "*Dans un contexte rÃ©el, on pourrait :*\r\n",
    "- **RÃ©duire le nombre dâ€™Ã©poques**,\r\n",
    "- Ou utiliser des techniques plus rapides comme :  \r\n",
    "  - **lâ€™importance permutationnelle**,  \r\n",
    "  - ou **les valeurs SHAP (SHapley Additive exPlanations)**.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "Ici, nous procÃ©dons Ã  cette approche complÃ¨te Ã  but **dÃ©monstratif**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['year','manufacturer','condition','cylinders','fuel','odometer',\n",
    "            'transmission','drive','type','paint_color','state','title_status',\n",
    "            'year_posted','month_posted','weekday_posted']\n",
    "\n",
    "feature_mae = {}  # dictionnaire pour stocker la MAE test sans chaque feature\n",
    "\n",
    "for feat in features:\n",
    "    # PrÃ©parer les donnÃ©es d'entraÃ®nement/val/test sans la feature 'feat'\n",
    "    if feat in num_cols:\n",
    "        # Retirer la colonne numÃ©rique directement\n",
    "        X_train_drop = X_train.drop(columns=[feat])\n",
    "        X_val_drop = X_val.drop(columns=[feat])\n",
    "        X_test_drop = X_test.drop(columns=[feat])\n",
    "    else:\n",
    "        # Retirer toutes les colonnes dummies correspondant Ã  la feature catÃ©gorielle\n",
    "        cols_to_drop = [col for col in X_train.columns if col.startswith(feat + \"_\")]\n",
    "        X_train_drop = X_train.drop(columns=cols_to_drop)\n",
    "        X_val_drop = X_val.drop(columns=cols_to_drop)\n",
    "        X_test_drop = X_test.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Convertir explicitement en numpy array de type float32\n",
    "    X_train_drop_np = X_train_drop.values.astype('float32')\n",
    "    X_val_drop_np   = X_val_drop.values.astype('float32')\n",
    "    X_test_drop_np  = X_test_drop.values.astype('float32')\n",
    "\n",
    "    # EntraÃ®ner un modÃ¨le Adam sur ces donnÃ©es modifiÃ©es\n",
    "    model_feat = keras.Sequential([\n",
    "        keras.Input(shape=(X_train_drop_np.shape[1],)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    model_feat.compile(optimizer=keras.optimizers.Adam(0.001), loss='mse', metrics=['mae'])\n",
    "    model_feat.fit(X_train_drop_np, y_train_np, epochs=100, batch_size=32,\n",
    "                   validation_data=(X_val_drop_np, y_val_np), verbose=0)\n",
    "\n",
    "    # Ã‰valuer la MAE sur le jeu de test\n",
    "    _, mae_no_feat = model_feat.evaluate(X_test_drop_np, y_test_np, verbose=0)\n",
    "    feature_mae[feat] = mae_no_feat\n",
    "    print(f\"Sans '{feat}' -> MAE test: {mae_no_feat:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois ce code exÃ©cutÃ©, nous avons dans feature_mae la MAE (sur test) du modÃ¨le entraÃ®nÃ© sans chaque feature. Rappelons que le modÃ¨le complet (avec toutes features) avait une MAE de base d'environ {baseline_mae:.2f} sur le test. Analysons l'augmentation d'erreur induite par l'absence de chaque colonne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'augmentation de MAE par rapport au modÃ¨le complet\n",
    "baseline = baseline_mae\n",
    "mae_increase = {feat: feature_mae[feat] - baseline for feat in feature_mae}\n",
    "# Trier les features par impact dÃ©croissant\n",
    "sorted_impacts = sorted(mae_increase.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Augmentation de MAE en retirant chaque feature :\")\n",
    "for feat, inc in sorted_impacts:\n",
    "    print(f\"{feat:15} +{inc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des impacts sous forme de barres horizontales\n",
    "feats = [f for f, inc in sorted_impacts]\n",
    "incs = [inc for f, inc in sorted_impacts]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(feats, incs, color='skyblue')\n",
    "plt.xlabel(\"Augmentation de la MAE (sans la feature)\")\n",
    "plt.ylabel(\"Feature retirÃ©e\")\n",
    "plt.title(\"Impact de la suppression d'une feature sur l'erreur de prÃ©diction\")\n",
    "plt.gca().invert_yaxis()  # mettre la plus impactante en haut\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InterprÃ©tation des rÃ©sultats d'ablation\n",
    "\n",
    "Lâ€™analyse par ablation permet dâ€™Ã©valuer lâ€™importance relative de chaque feature. Voici les principales observations :\n",
    "\n",
    "---\n",
    "\n",
    "## Features les plus dÃ©terminantes :\n",
    "\n",
    "- **year (annÃ©e du vÃ©hicule)** :  \n",
    "  La suppression de cette colonne entraÃ®ne une nette dÃ©gradation de la MAE. Câ€™est cohÃ©rent avec le fait que lâ€™Ã¢ge du vÃ©hicule est un facteur dÃ©terminant de sa valeur.\n",
    "\n",
    "- **odometer (kilomÃ©trage)** :  \n",
    "  Lâ€™impact est Ã©galement trÃ¨s marquÃ©. Plus une voiture a roulÃ©, plus sa valeur tend Ã  diminuer. Le modÃ¨le utilise donc fortement cette information.\n",
    "\n",
    "- **manufacturer (marque)** :  \n",
    "  Lâ€™absence de cette variable empÃªche le modÃ¨le de distinguer des marques aux positionnements diffÃ©rents (ex. BMW vs Honda), ce qui affecte directement la qualitÃ© des prÃ©dictions.\n",
    "\n",
    "- **condition** et **title_status** :  \n",
    "  Ces deux variables apportent des informations critiques sur lâ€™Ã©tat et lâ€™historique du vÃ©hicule (ex. voiture accidentÃ©e ou remise Ã  neuf), expliquant leur rÃ´le important.\n",
    "\n",
    "- **type (catÃ©gorie du vÃ©hicule)** :  \n",
    "  Son retrait a Ã©galement un effet significatif. Certains types (camionnettes, SUV, sportives) sont associÃ©s Ã  des gammes de prix bien distinctes.\n",
    "\n",
    "---\n",
    "\n",
    "## Features avec impact faible ou nÃ©gligeable :\n",
    "\n",
    "- **paint_color (couleur)** :  \n",
    "  TrÃ¨s faible influence. La couleur n'affecte que marginalement le prix de vente, sauf cas trÃ¨s particuliers.\n",
    "\n",
    "- **state (Ã‰tat gÃ©ographique)** :  \n",
    "  La suppression de cette colonne nâ€™entraÃ®ne quâ€™une variation minime de la MAE. Les diffÃ©rences rÃ©gionales de prix sont peu marquÃ©es dans ce dataset.\n",
    "\n",
    "- **year_posted, month_posted, weekday_posted** :  \n",
    "  Ces variables liÃ©es Ã  la date de publication ne semblent pas utiles pour la prÃ©diction du prix. Elles peuvent reflÃ©ter des effets saisonniers ou de marchÃ©, mais dans ce cas prÃ©cis, leur impact est nÃ©gligeable.\n",
    "\n",
    "---\n",
    "\n",
    "## RÃ©sumÃ© :\n",
    "\n",
    "Les variables **mÃ©caniques et intrinsÃ¨ques** du vÃ©hicule (annÃ©e, kilomÃ©trage, Ã©tat, marque, statut, type) sont celles qui influencent le plus fortement le prix.  \n",
    "Les variables **cosmÃ©tiques ou contextuelles** (couleur, date de publication, localisation) ont un effet trÃ¨s limitÃ©.\n",
    "\n",
    "Cela confirme lâ€™intuition du marchÃ© automobile : ce sont les caractÃ©ristiques physiques et techniques du vÃ©hicule qui dÃ©terminent sa valeur perÃ§ue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous avons construit un modÃ¨le de rÃ©gression pour estimer le prix de vÃ©hicules d'occasion Ã  partir de donnÃ©es issues d'annonces Craigslist.\r\n",
    "\r\n",
    "AprÃ¨s un travail de prÃ©paration des donnÃ©es (nettoyage, encodage des variables catÃ©gorielles, normalisation), nous avons entraÃ®nÃ© un rÃ©seau de neurones simple et comparÃ© l'effet de diffÃ©rents algorithmes d'optimisation sur la convergence du modÃ¨le.\r\n",
    "\r\n",
    "Les rÃ©sultats ont montrÃ© que :\r\n",
    "\r\n",
    "- Adam et RMSprop convergent plus rapidement que SGD, atteignant une erreur (MAE) plus faible en moins dâ€™Ã©poques.\r\n",
    "- Adagrad converge rapidement au dÃ©but mais stagne ensuite.\r\n",
    "- SGD est plus lent sans rÃ©glage particulier, mais pourrait atteindre des performances similaires avec plus dâ€™Ã©poques ou un learning rate mieux adaptÃ©.\r\n",
    "\r\n",
    "Ces observations confirment que les optimiseurs adaptatifs sont souvent plus efficaces pour des modÃ¨les de ce type, en particulier Adam, qui sâ€™avÃ¨re Ãªtre un bon choix par dÃ©faut.\r\n",
    "\r\n",
    "Lâ€™analyse par ablation a mis en Ã©vidence que les variables les plus importantes pour prÃ©dire le prix sont lâ€™annÃ©e du vÃ©hicule, le kilomÃ©trage, lâ€™Ã©tat gÃ©nÃ©ral, le statut du titre et la marque. Ces Ã©lÃ©ments sont effectivement ceux que les acheteurs considÃ¨rent en prioritÃ©.\r\n",
    "\r\n",
    "Les variables comme la couleur, la date de publication ou lâ€™Ã‰tat gÃ©ographique ont peu dâ€™influence et peuvent Ãªtre ignorÃ©es sans perte significative de performance.\r\n",
    "\r\n",
    "En conclusion, nous avons obtenu un modÃ¨le atteignant une MAE dâ€™environ **{baseline_mae:.2f} â‚¬** sur le jeu de test, ce qui reprÃ©sente une erreur moyenne raisonnable compte tenu du prix typique des vÃ©hicules.\r\n",
    "\r\n",
    "Des pistes dâ€™amÃ©lioration possibles incluent :\r\n",
    "\r\n",
    "- IntÃ©grer le modÃ¨le exact du vÃ©hicule via des techniques dâ€™encodage plus avancÃ©es (embedding).\r\n",
    "- Ajuster lâ€™architecture du rÃ©seau (nombre de couches, de neurones).\r\n",
    "- Utiliser des techniques de rÃ©gularisation (dropout, weight decay).\r\n",
    "- Comparer avec dâ€™autres familles de modÃ¨les (arbres de dÃ©cision, forÃªts alÃ©atoires, XGBoost...).\r\n",
    "\r\n",
    "Globalement, ce projet montre quâ€™un rÃ©seau de neurones simple, correctement entraÃ®nÃ© avec un optimiseur comme Adam, permet dâ€™obtenir des rÃ©sultats solides et cohÃ©rents avec les connaissances du domaine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
